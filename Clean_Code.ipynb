{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=pd.read_csv(\"cleaneddata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y=pd.read_csv(\"FinalY.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=Y.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=X.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3151, 37) (3151, 1)\n",
      "(1698, 37) (1698, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.advanced_activations import ThresholdedReLU\n",
    "from keras.layers.advanced_activations import ELU\n",
    "\n",
    "features=X.shape[1]\n",
    "model=Sequential()\n",
    "model.add(Dense(256,input_dim=(features),activation=PReLU()))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(128,activation=PReLU()))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(128,activation=PReLU()))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(256,activation=PReLU()))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(64,activation=PReLU()))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(64,activation=ThresholdedReLU()))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(32,activation=ThresholdedReLU()))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(32,activation=ThresholdedReLU()))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(16,activation=ThresholdedReLU()))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(16,activation=ELU()))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/praveenkumar/anaconda/envs/py3/lib/python3.5/site-packages/keras/activations.py:235: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/Users/praveenkumar/anaconda/envs/py3/lib/python3.5/site-packages/keras/activations.py:235: UserWarning: Do not pass a layer instance (such as ThresholdedReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.advanced_activations import ThresholdedReLU\n",
    "from keras.layers.advanced_activations import ELU\n",
    "\n",
    "features=X.shape[1]\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(256,input_dim=(features),activation=PReLU()))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Dense(128,activation=PReLU()))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Dense(64,activation=PReLU()))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Dense(32,activation=ThresholdedReLU()))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Dense(16,activation=ThresholdedReLU()))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               9728      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 53,505\n",
      "Trainable params: 53,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "opt=Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\", optimizer = opt,metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3151 samples, validate on 1698 samples\n",
      "Epoch 1/300\n",
      "3151/3151 [==============================] - 1s 398us/step - loss: 145753.3893 - acc: 0.0117 - val_loss: 47380.4862 - val_acc: 0.0118\n",
      "Epoch 2/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 54170.7933 - acc: 0.0190 - val_loss: 48061.0539 - val_acc: 0.0135\n",
      "Epoch 3/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 74344.0129 - acc: 0.0146 - val_loss: 47559.8433 - val_acc: 0.0094\n",
      "Epoch 4/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 51595.7771 - acc: 0.0111 - val_loss: 47057.2339 - val_acc: 0.0141\n",
      "Epoch 5/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 52556.5923 - acc: 0.0092 - val_loss: 45537.0920 - val_acc: 0.0088\n",
      "Epoch 6/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 75432.9268 - acc: 0.0079 - val_loss: 44436.0188 - val_acc: 0.0065\n",
      "Epoch 7/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 45892.7375 - acc: 0.0083 - val_loss: 45658.2027 - val_acc: 0.0082\n",
      "Epoch 8/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 46939.5709 - acc: 0.0070 - val_loss: 45220.6336 - val_acc: 0.0088\n",
      "Epoch 9/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 49946.6865 - acc: 0.0083 - val_loss: 44787.7664 - val_acc: 0.0053\n",
      "Epoch 10/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 43668.6170 - acc: 0.0079 - val_loss: 44375.8362 - val_acc: 0.0047\n",
      "Epoch 11/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 43268.6399 - acc: 0.0041 - val_loss: 43978.4513 - val_acc: 0.0012\n",
      "Epoch 12/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 42896.4780 - acc: 0.0060 - val_loss: 43595.5214 - val_acc: 0.0035\n",
      "Epoch 13/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 42780.6432 - acc: 0.0038 - val_loss: 43225.2534 - val_acc: 0.0059\n",
      "Epoch 14/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 45167.3836 - acc: 0.0048 - val_loss: 42875.9882 - val_acc: 0.0047\n",
      "Epoch 15/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 41804.3605 - acc: 0.0048 - val_loss: 42536.7071 - val_acc: 0.0047\n",
      "Epoch 16/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 41591.5964 - acc: 0.0044 - val_loss: 42213.4255 - val_acc: 0.0053\n",
      "Epoch 17/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 41234.3517 - acc: 0.0041 - val_loss: 41900.3058 - val_acc: 0.0041\n",
      "Epoch 18/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 40864.4278 - acc: 0.0032 - val_loss: 41602.1059 - val_acc: 0.0047\n",
      "Epoch 19/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 41807.7865 - acc: 0.0057 - val_loss: 41321.2046 - val_acc: 0.0047\n",
      "Epoch 20/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 40314.4924 - acc: 0.0035 - val_loss: 41049.8590 - val_acc: 0.0041\n",
      "Epoch 21/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 40060.9233 - acc: 0.0022 - val_loss: 40791.7530 - val_acc: 0.0018\n",
      "Epoch 22/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 39806.0038 - acc: 0.0044 - val_loss: 40546.6746 - val_acc: 0.0029\n",
      "Epoch 23/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 39577.2460 - acc: 0.0035 - val_loss: 40314.3325 - val_acc: 0.0012\n",
      "Epoch 24/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 39350.2725 - acc: 0.0029 - val_loss: 40094.1768 - val_acc: 0.0024\n",
      "Epoch 25/300\n",
      "3151/3151 [==============================] - 1s 240us/step - loss: 39145.3290 - acc: 0.0035 - val_loss: 39886.1167 - val_acc: 0.0012\n",
      "Epoch 26/300\n",
      "3151/3151 [==============================] - 1s 234us/step - loss: 39007.6500 - acc: 0.0035 - val_loss: 39689.8041 - val_acc: 0.0024\n",
      "Epoch 27/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 38817.9867 - acc: 0.0029 - val_loss: 39504.1618 - val_acc: 0.0035\n",
      "Epoch 28/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 48123.8275 - acc: 0.0044 - val_loss: 39339.2806 - val_acc: 0.0047\n",
      "Epoch 29/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 38449.9300 - acc: 0.0032 - val_loss: 39176.7934 - val_acc: 0.0035\n",
      "Epoch 30/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 38329.1624 - acc: 0.0019 - val_loss: 39023.5036 - val_acc: 5.8893e-04\n",
      "Epoch 31/300\n",
      "3151/3151 [==============================] - 1s 236us/step - loss: 38144.4229 - acc: 0.0025 - val_loss: 38879.5578 - val_acc: 0.0012\n",
      "Epoch 32/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 38056.5548 - acc: 6.3472e-04 - val_loss: 38744.9950 - val_acc: 0.0024\n",
      "Epoch 33/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 161403.7850 - acc: 0.0019 - val_loss: 38628.6216 - val_acc: 5.8893e-04\n",
      "Epoch 34/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 37792.0556 - acc: 0.0016 - val_loss: 38528.6637 - val_acc: 0.0024\n",
      "Epoch 35/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 37687.2406 - acc: 0.0025 - val_loss: 38430.8531 - val_acc: 0.0018\n",
      "Epoch 36/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 37608.6848 - acc: 0.0022 - val_loss: 38335.9234 - val_acc: 0.0012\n",
      "Epoch 37/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 37505.6397 - acc: 0.0032 - val_loss: 38244.7632 - val_acc: 0.0012\n",
      "Epoch 38/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 37423.3945 - acc: 0.0038 - val_loss: 38157.8290 - val_acc: 0.0029\n",
      "Epoch 39/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 37427.4425 - acc: 3.1736e-04 - val_loss: 38075.1503 - val_acc: 0.0029\n",
      "Epoch 40/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 45174.4040 - acc: 0.0013 - val_loss: 38002.5674 - val_acc: 0.0053\n",
      "Epoch 41/300\n",
      "3151/3151 [==============================] - 1s 227us/step - loss: 37197.3899 - acc: 0.0029 - val_loss: 37930.8003 - val_acc: 0.0018\n",
      "Epoch 42/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 37444.3612 - acc: 9.5208e-04 - val_loss: 37864.4487 - val_acc: 0.0041\n",
      "Epoch 43/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 37072.0993 - acc: 0.0019 - val_loss: 37802.1385 - val_acc: 0.0012\n",
      "Epoch 44/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 37034.5645 - acc: 0.0016 - val_loss: 37744.3347 - val_acc: 0.0029\n",
      "Epoch 45/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36973.1273 - acc: 0.0016 - val_loss: 37690.9173 - val_acc: 0.0018\n",
      "Epoch 46/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36914.8055 - acc: 0.0019 - val_loss: 37641.6374 - val_acc: 0.0024\n",
      "Epoch 47/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36871.0927 - acc: 0.0025 - val_loss: 37596.2366 - val_acc: 0.0018\n",
      "Epoch 48/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 36831.2229 - acc: 0.0019 - val_loss: 37554.5589 - val_acc: 5.8893e-04\n",
      "Epoch 49/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36791.1291 - acc: 0.0019 - val_loss: 37516.1945 - val_acc: 0.0018\n",
      "Epoch 50/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 38072.1205 - acc: 6.3472e-04 - val_loss: 37480.0338 - val_acc: 0.0024\n",
      "Epoch 51/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36732.0368 - acc: 0.0032 - val_loss: 37448.0037 - val_acc: 0.0024\n",
      "Epoch 52/300\n",
      "3151/3151 [==============================] - 1s 237us/step - loss: 36700.5209 - acc: 9.5208e-04 - val_loss: 37418.7172 - val_acc: 0.0012\n",
      "Epoch 53/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 36674.9913 - acc: 0.0013 - val_loss: 37391.9187 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 36651.7411 - acc: 0.0016 - val_loss: 37367.4078 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36630.5876 - acc: 0.0019 - val_loss: 37345.0126 - val_acc: 0.0018\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3151/3151 [==============================] - 1s 215us/step - loss: 36611.3577 - acc: 0.0013 - val_loss: 37324.5600 - val_acc: 5.8893e-04\n",
      "Epoch 57/300\n",
      "3151/3151 [==============================] - 1s 209us/step - loss: 36593.8889 - acc: 0.0019 - val_loss: 37305.8845 - val_acc: 5.8893e-04\n",
      "Epoch 58/300\n",
      "3151/3151 [==============================] - 1s 210us/step - loss: 36578.0311 - acc: 0.0025 - val_loss: 37288.8444 - val_acc: 0.0012\n",
      "Epoch 59/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36563.6430 - acc: 0.0022 - val_loss: 37273.2920 - val_acc: 0.0012\n",
      "Epoch 60/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36550.5975 - acc: 9.5208e-04 - val_loss: 37259.1141 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 36538.7751 - acc: 9.5208e-04 - val_loss: 37246.1816 - val_acc: 0.0024\n",
      "Epoch 62/300\n",
      "3151/3151 [==============================] - 1s 226us/step - loss: 36528.0642 - acc: 0.0032 - val_loss: 37234.3921 - val_acc: 0.0024\n",
      "Epoch 63/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 36518.3640 - acc: 0.0032 - val_loss: 37223.6411 - val_acc: 0.0029\n",
      "Epoch 64/300\n",
      "3151/3151 [==============================] - 1s 224us/step - loss: 36509.5831 - acc: 0.0016 - val_loss: 37213.8355 - val_acc: 0.0029\n",
      "Epoch 65/300\n",
      "3151/3151 [==============================] - 1s 221us/step - loss: 36501.6372 - acc: 0.0016 - val_loss: 37204.8957 - val_acc: 0.0029\n",
      "Epoch 66/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 36494.4485 - acc: 0.0019 - val_loss: 37196.7456 - val_acc: 5.8893e-04\n",
      "Epoch 67/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 36736.2664 - acc: 0.0016 - val_loss: 37189.1602 - val_acc: 5.8893e-04\n",
      "Epoch 68/300\n",
      "3151/3151 [==============================] - 1s 209us/step - loss: 36481.9532 - acc: 0.0029 - val_loss: 37182.4093 - val_acc: 0.0024\n",
      "Epoch 69/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 36476.4105 - acc: 0.0016 - val_loss: 37176.2413 - val_acc: 0.0024\n",
      "Epoch 70/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 36536.9992 - acc: 0.0016 - val_loss: 37170.5045 - val_acc: 0.0024\n",
      "Epoch 71/300\n",
      "3151/3151 [==============================] - 1s 210us/step - loss: 36467.4560 - acc: 6.3472e-04 - val_loss: 37165.3764 - val_acc: 0.0018\n",
      "Epoch 72/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 36463.5503 - acc: 0.0013 - val_loss: 37160.6905 - val_acc: 0.0018\n",
      "Epoch 73/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36466.3813 - acc: 0.0013 - val_loss: 37156.4271 - val_acc: 0.0018\n",
      "Epoch 74/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36456.8455 - acc: 9.5208e-04 - val_loss: 37152.5204 - val_acc: 0.0018\n",
      "Epoch 75/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36453.9642 - acc: 0.0000e+00 - val_loss: 37148.9466 - val_acc: 0.0018\n",
      "Epoch 76/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36451.3623 - acc: 0.0000e+00 - val_loss: 37145.6846 - val_acc: 0.0018\n",
      "Epoch 77/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36449.1779 - acc: 0.0000e+00 - val_loss: 37142.6975 - val_acc: 0.0018\n",
      "Epoch 78/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36446.8908 - acc: 0.0000e+00 - val_loss: 37139.9627 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 36444.9751 - acc: 0.0013 - val_loss: 37137.4615 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36443.2447 - acc: 0.0013 - val_loss: 37135.1701 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36441.6824 - acc: 0.0013 - val_loss: 37133.0698 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36485.0788 - acc: 0.0013 - val_loss: 37131.1973 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36439.0318 - acc: 0.0013 - val_loss: 37129.4286 - val_acc: 0.0012\n",
      "Epoch 84/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36437.8795 - acc: 9.5208e-04 - val_loss: 37127.8055 - val_acc: 0.0012\n",
      "Epoch 85/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 36965.0282 - acc: 6.3472e-04 - val_loss: 37126.4940 - val_acc: 0.0012\n",
      "Epoch 86/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 307571.5093 - acc: 6.3472e-04 - val_loss: 37122.6918 - val_acc: 0.0012\n",
      "Epoch 87/300\n",
      "3151/3151 [==============================] - 1s 224us/step - loss: 36433.5562 - acc: 6.3472e-04 - val_loss: 37121.9214 - val_acc: 0.0012\n",
      "Epoch 88/300\n",
      "3151/3151 [==============================] - 1s 235us/step - loss: 36434.2072 - acc: 6.3472e-04 - val_loss: 37121.2497 - val_acc: 0.0012\n",
      "Epoch 89/300\n",
      "3151/3151 [==============================] - 1s 220us/step - loss: 36432.7964 - acc: 6.3472e-04 - val_loss: 37120.5564 - val_acc: 0.0012\n",
      "Epoch 90/300\n",
      "3151/3151 [==============================] - 1s 224us/step - loss: 36432.4028 - acc: 0.0013 - val_loss: 37119.8542 - val_acc: 0.0018\n",
      "Epoch 91/300\n",
      "3151/3151 [==============================] - 1s 226us/step - loss: 36432.0117 - acc: 0.0013 - val_loss: 37119.1570 - val_acc: 0.0018\n",
      "Epoch 92/300\n",
      "3151/3151 [==============================] - 1s 227us/step - loss: 36429.5860 - acc: 0.0013 - val_loss: 37118.4690 - val_acc: 0.0018\n",
      "Epoch 93/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 36431.8772 - acc: 0.0013 - val_loss: 37117.8033 - val_acc: 0.0018\n",
      "Epoch 94/300\n",
      "3151/3151 [==============================] - 1s 221us/step - loss: 36440.4533 - acc: 0.0013 - val_loss: 37117.1640 - val_acc: 0.0018\n",
      "Epoch 95/300\n",
      "3151/3151 [==============================] - 1s 220us/step - loss: 36430.5784 - acc: 0.0013 - val_loss: 37116.5570 - val_acc: 0.0018\n",
      "Epoch 96/300\n",
      "3151/3151 [==============================] - 1s 221us/step - loss: 36430.2709 - acc: 0.0013 - val_loss: 37115.9834 - val_acc: 0.0018\n",
      "Epoch 97/300\n",
      "3151/3151 [==============================] - 1s 222us/step - loss: 36429.9869 - acc: 0.0013 - val_loss: 37115.4425 - val_acc: 0.0018\n",
      "Epoch 98/300\n",
      "3151/3151 [==============================] - 1s 223us/step - loss: 36429.7259 - acc: 0.0013 - val_loss: 37114.9407 - val_acc: 0.0018\n",
      "Epoch 99/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 36429.4862 - acc: 0.0013 - val_loss: 37114.4651 - val_acc: 0.0018\n",
      "Epoch 100/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 36429.2673 - acc: 0.0013 - val_loss: 37114.0254 - val_acc: 0.0018\n",
      "Epoch 101/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 36429.0688 - acc: 0.0013 - val_loss: 37113.6160 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36428.8879 - acc: 9.5208e-04 - val_loss: 37113.2335 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 36428.7243 - acc: 9.5208e-04 - val_loss: 37112.8800 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36428.5749 - acc: 9.5208e-04 - val_loss: 37112.5463 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 36428.4404 - acc: 9.5208e-04 - val_loss: 37112.2417 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 71865.0879 - acc: 9.5208e-04 - val_loss: 37112.7662 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36428.4943 - acc: 9.5208e-04 - val_loss: 37112.4983 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36428.3835 - acc: 9.5208e-04 - val_loss: 37112.2184 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36451.4561 - acc: 9.5208e-04 - val_loss: 37111.9222 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 36429.4758 - acc: 9.5208e-04 - val_loss: 37111.6727 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36538.5117 - acc: 9.5208e-04 - val_loss: 37111.3793 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.9849 - acc: 9.5208e-04 - val_loss: 37111.1554 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "3151/3151 [==============================] - 1s 210us/step - loss: 36427.9102 - acc: 9.5208e-04 - val_loss: 37110.9459 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "3151/3151 [==============================] - 1s 209us/step - loss: 36427.8420 - acc: 9.5208e-04 - val_loss: 37110.7475 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36427.7795 - acc: 9.5208e-04 - val_loss: 37110.5652 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "3151/3151 [==============================] - 1s 210us/step - loss: 36427.7218 - acc: 9.5208e-04 - val_loss: 37110.3921 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36427.6699 - acc: 9.5208e-04 - val_loss: 37110.2283 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.6224 - acc: 9.5208e-04 - val_loss: 37110.0754 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 36427.5797 - acc: 9.5208e-04 - val_loss: 37109.9356 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "3151/3151 [==============================] - 1s 210us/step - loss: 36427.5405 - acc: 9.5208e-04 - val_loss: 37109.8007 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "3151/3151 [==============================] - 1s 210us/step - loss: 36427.5051 - acc: 9.5208e-04 - val_loss: 37109.6755 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36427.4730 - acc: 9.5208e-04 - val_loss: 37109.5560 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36427.4436 - acc: 9.5208e-04 - val_loss: 37109.4449 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "3151/3151 [==============================] - 1s 210us/step - loss: 36427.4173 - acc: 9.5208e-04 - val_loss: 37109.3424 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "3151/3151 [==============================] - 1s 210us/step - loss: 36427.3936 - acc: 9.5208e-04 - val_loss: 37109.2447 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 36427.3714 - acc: 9.5208e-04 - val_loss: 37109.1531 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 36427.3521 - acc: 9.5208e-04 - val_loss: 37109.0709 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "3151/3151 [==============================] - 1s 210us/step - loss: 36427.3214 - acc: 9.5208e-04 - val_loss: 37108.9901 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "3151/3151 [==============================] - 1s 220us/step - loss: 36427.3184 - acc: 9.5208e-04 - val_loss: 37108.9115 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36427.3040 - acc: 6.3472e-04 - val_loss: 37108.8409 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36427.2907 - acc: 6.3472e-04 - val_loss: 37108.7736 - val_acc: 0.0012\n",
      "Epoch 132/300\n",
      "3151/3151 [==============================] - 1s 225us/step - loss: 36518.1563 - acc: 6.3472e-04 - val_loss: 37108.7368 - val_acc: 0.0012\n",
      "Epoch 133/300\n",
      "3151/3151 [==============================] - 1s 209us/step - loss: 36427.2720 - acc: 6.3472e-04 - val_loss: 37108.6760 - val_acc: 0.0012\n",
      "Epoch 134/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 36426.9226 - acc: 3.1736e-04 - val_loss: 37108.6158 - val_acc: 0.0012\n",
      "Epoch 135/300\n",
      "3151/3151 [==============================] - 1s 209us/step - loss: 36427.2518 - acc: 3.1736e-04 - val_loss: 37108.5593 - val_acc: 0.0012\n",
      "Epoch 136/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36427.2435 - acc: 6.3472e-04 - val_loss: 37108.5086 - val_acc: 0.0012\n",
      "Epoch 137/300\n",
      "3151/3151 [==============================] - 1s 209us/step - loss: 36427.2362 - acc: 6.3472e-04 - val_loss: 37108.4596 - val_acc: 0.0012\n",
      "Epoch 138/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36427.2292 - acc: 9.5208e-04 - val_loss: 37108.4155 - val_acc: 0.0012\n",
      "Epoch 139/300\n",
      "3151/3151 [==============================] - 1s 208us/step - loss: 36427.2234 - acc: 9.5208e-04 - val_loss: 37108.3755 - val_acc: 0.0012\n",
      "Epoch 140/300\n",
      "3151/3151 [==============================] - 1s 209us/step - loss: 36427.2175 - acc: 9.5208e-04 - val_loss: 37108.3322 - val_acc: 0.0012\n",
      "Epoch 141/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36427.2126 - acc: 9.5208e-04 - val_loss: 37108.2965 - val_acc: 0.0012\n",
      "Epoch 142/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.2080 - acc: 9.5208e-04 - val_loss: 37108.2580 - val_acc: 0.0012\n",
      "Epoch 143/300\n",
      "3151/3151 [==============================] - 1s 208us/step - loss: 36427.2039 - acc: 9.5208e-04 - val_loss: 37108.2269 - val_acc: 0.0012\n",
      "Epoch 144/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 36427.1995 - acc: 9.5208e-04 - val_loss: 37108.1956 - val_acc: 0.0012\n",
      "Epoch 145/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36427.1962 - acc: 9.5208e-04 - val_loss: 37108.1658 - val_acc: 0.0012\n",
      "Epoch 146/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.1931 - acc: 9.5208e-04 - val_loss: 37108.1352 - val_acc: 0.0012\n",
      "Epoch 147/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.1900 - acc: 9.5208e-04 - val_loss: 37108.1076 - val_acc: 0.0012\n",
      "Epoch 148/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36427.1874 - acc: 9.5208e-04 - val_loss: 37108.0844 - val_acc: 0.0012\n",
      "Epoch 149/300\n",
      "3151/3151 [==============================] - 1s 222us/step - loss: 36427.1853 - acc: 9.5208e-04 - val_loss: 37108.0572 - val_acc: 0.0012\n",
      "Epoch 150/300\n",
      "3151/3151 [==============================] - 1s 223us/step - loss: 36427.1829 - acc: 9.5208e-04 - val_loss: 37108.0348 - val_acc: 0.0012\n",
      "Epoch 151/300\n",
      "3151/3151 [==============================] - 1s 220us/step - loss: 36427.1808 - acc: 9.5208e-04 - val_loss: 37108.0158 - val_acc: 0.0012\n",
      "Epoch 152/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 36427.1795 - acc: 9.5208e-04 - val_loss: 37107.9948 - val_acc: 0.0012\n",
      "Epoch 153/300\n",
      "3151/3151 [==============================] - 1s 280us/step - loss: 36427.1774 - acc: 9.5208e-04 - val_loss: 37107.9752 - val_acc: 0.0012\n",
      "Epoch 154/300\n",
      "3151/3151 [==============================] - 1s 226us/step - loss: 36427.1761 - acc: 9.5208e-04 - val_loss: 37107.9567 - val_acc: 0.0012\n",
      "Epoch 155/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 36427.1745 - acc: 9.5208e-04 - val_loss: 37107.9367 - val_acc: 0.0012\n",
      "Epoch 156/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 36427.1734 - acc: 9.5208e-04 - val_loss: 37107.9236 - val_acc: 0.0012\n",
      "Epoch 157/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 36427.1722 - acc: 9.5208e-04 - val_loss: 37107.9057 - val_acc: 0.0012\n",
      "Epoch 158/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 36427.1713 - acc: 9.5208e-04 - val_loss: 37107.8928 - val_acc: 0.0012\n",
      "Epoch 159/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 36427.1702 - acc: 9.5208e-04 - val_loss: 37107.8788 - val_acc: 0.0012\n",
      "Epoch 160/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 36427.1695 - acc: 9.5208e-04 - val_loss: 37107.8639 - val_acc: 0.0012\n",
      "Epoch 161/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36427.1684 - acc: 9.5208e-04 - val_loss: 37107.8513 - val_acc: 0.0012\n",
      "Epoch 162/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 36427.1678 - acc: 9.5208e-04 - val_loss: 37107.8393 - val_acc: 0.0012\n",
      "Epoch 163/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 36427.1673 - acc: 9.5208e-04 - val_loss: 37107.8291 - val_acc: 0.0012\n",
      "Epoch 164/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 36427.1665 - acc: 9.5208e-04 - val_loss: 37107.8186 - val_acc: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/300\n",
      "3151/3151 [==============================] - 1s 209us/step - loss: 36427.1658 - acc: 9.5208e-04 - val_loss: 37107.8092 - val_acc: 0.0012\n",
      "Epoch 166/300\n",
      "3151/3151 [==============================] - 1s 209us/step - loss: 36427.1653 - acc: 9.5208e-04 - val_loss: 37107.7994 - val_acc: 0.0012\n",
      "Epoch 167/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36427.1650 - acc: 9.5208e-04 - val_loss: 37107.7903 - val_acc: 0.0012\n",
      "Epoch 168/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36427.1643 - acc: 9.5208e-04 - val_loss: 37107.7809 - val_acc: 0.0012\n",
      "Epoch 169/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36427.1640 - acc: 9.5208e-04 - val_loss: 37107.7711 - val_acc: 0.0012\n",
      "Epoch 170/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.1637 - acc: 9.5208e-04 - val_loss: 37107.7650 - val_acc: 0.0012\n",
      "Epoch 171/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36427.1637 - acc: 9.5208e-04 - val_loss: 37107.7583 - val_acc: 0.0012\n",
      "Epoch 172/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.1631 - acc: 9.5208e-04 - val_loss: 37107.7488 - val_acc: 0.0012\n",
      "Epoch 173/300\n",
      "3151/3151 [==============================] - 1s 220us/step - loss: 36427.1629 - acc: 9.5208e-04 - val_loss: 37107.7457 - val_acc: 0.0012\n",
      "Epoch 174/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36427.1627 - acc: 9.5208e-04 - val_loss: 37107.7361 - val_acc: 0.0012\n",
      "Epoch 175/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.1625 - acc: 9.5208e-04 - val_loss: 37107.7326 - val_acc: 0.0012\n",
      "Epoch 176/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.1622 - acc: 9.5208e-04 - val_loss: 37107.7272 - val_acc: 0.0012\n",
      "Epoch 177/300\n",
      "3151/3151 [==============================] - 1s 236us/step - loss: 36427.1617 - acc: 9.5208e-04 - val_loss: 37107.7188 - val_acc: 0.0012\n",
      "Epoch 178/300\n",
      "3151/3151 [==============================] - 1s 209us/step - loss: 36427.1616 - acc: 9.5208e-04 - val_loss: 37107.7180 - val_acc: 0.0012\n",
      "Epoch 179/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.1615 - acc: 9.5208e-04 - val_loss: 37107.7101 - val_acc: 0.0012\n",
      "Epoch 180/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36427.1612 - acc: 9.5208e-04 - val_loss: 37107.7057 - val_acc: 0.0012\n",
      "Epoch 181/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36427.1613 - acc: 9.5208e-04 - val_loss: 37107.7030 - val_acc: 0.0012\n",
      "Epoch 182/300\n",
      "3151/3151 [==============================] - 1s 210us/step - loss: 36427.1610 - acc: 9.5208e-04 - val_loss: 37107.6970 - val_acc: 0.0012\n",
      "Epoch 183/300\n",
      "3151/3151 [==============================] - 1s 209us/step - loss: 36427.1608 - acc: 9.5208e-04 - val_loss: 37107.6935 - val_acc: 0.0012\n",
      "Epoch 184/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36427.1608 - acc: 9.5208e-04 - val_loss: 37107.6916 - val_acc: 0.0012\n",
      "Epoch 185/300\n",
      "3151/3151 [==============================] - 1s 210us/step - loss: 36427.1604 - acc: 9.5208e-04 - val_loss: 37107.6864 - val_acc: 0.0012\n",
      "Epoch 186/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 36427.1606 - acc: 9.5208e-04 - val_loss: 37107.6834 - val_acc: 0.0012\n",
      "Epoch 187/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.1606 - acc: 9.5208e-04 - val_loss: 37107.6813 - val_acc: 0.0012\n",
      "Epoch 188/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 36427.1605 - acc: 9.5208e-04 - val_loss: 37107.6758 - val_acc: 0.0012\n",
      "Epoch 189/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36427.1604 - acc: 9.5208e-04 - val_loss: 37107.6737 - val_acc: 0.0012\n",
      "Epoch 190/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36427.1604 - acc: 9.5208e-04 - val_loss: 37107.6707 - val_acc: 0.0012\n",
      "Epoch 191/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 36427.1597 - acc: 9.5208e-04 - val_loss: 37107.6670 - val_acc: 0.0012\n",
      "Epoch 192/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.1602 - acc: 9.5208e-04 - val_loss: 37107.6666 - val_acc: 0.0012\n",
      "Epoch 193/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36427.1599 - acc: 9.5208e-04 - val_loss: 37107.6621 - val_acc: 0.0012\n",
      "Epoch 194/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36427.1599 - acc: 9.5208e-04 - val_loss: 37107.6592 - val_acc: 0.0012\n",
      "Epoch 195/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36427.1599 - acc: 9.5208e-04 - val_loss: 37107.6569 - val_acc: 0.0012\n",
      "Epoch 196/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36427.1596 - acc: 9.5208e-04 - val_loss: 37107.6575 - val_acc: 0.0012\n",
      "Epoch 197/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36435.0296 - acc: 9.5208e-04 - val_loss: 37107.6421 - val_acc: 0.0012\n",
      "Epoch 198/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6394 - val_acc: 0.0012\n",
      "Epoch 199/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36427.1594 - acc: 9.5208e-04 - val_loss: 37107.6410 - val_acc: 0.0012\n",
      "Epoch 200/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6400 - val_acc: 0.0012\n",
      "Epoch 201/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 36427.1591 - acc: 9.5208e-04 - val_loss: 37107.6397 - val_acc: 0.0012\n",
      "Epoch 202/300\n",
      "3151/3151 [==============================] - 1s 209us/step - loss: 36427.1589 - acc: 9.5208e-04 - val_loss: 37107.6385 - val_acc: 0.0012\n",
      "Epoch 203/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6370 - val_acc: 0.0012\n",
      "Epoch 204/300\n",
      "3151/3151 [==============================] - 1s 210us/step - loss: 36427.1588 - acc: 9.5208e-04 - val_loss: 37107.6333 - val_acc: 0.0012\n",
      "Epoch 205/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6351 - val_acc: 0.0012\n",
      "Epoch 206/300\n",
      "3151/3151 [==============================] - 1s 220us/step - loss: 36427.1592 - acc: 9.5208e-04 - val_loss: 37107.6343 - val_acc: 0.0012\n",
      "Epoch 207/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6310 - val_acc: 0.0012\n",
      "Epoch 208/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 36427.1588 - acc: 9.5208e-04 - val_loss: 37107.6330 - val_acc: 0.0012\n",
      "Epoch 209/300\n",
      "3151/3151 [==============================] - 1s 240us/step - loss: 36427.1589 - acc: 9.5208e-04 - val_loss: 37107.6304 - val_acc: 0.0012\n",
      "Epoch 210/300\n",
      "3151/3151 [==============================] - 1s 210us/step - loss: 36427.1591 - acc: 9.5208e-04 - val_loss: 37107.6319 - val_acc: 0.0012\n",
      "Epoch 211/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 36427.1589 - acc: 9.5208e-04 - val_loss: 37107.6315 - val_acc: 0.0012\n",
      "Epoch 212/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36427.1587 - acc: 9.5208e-04 - val_loss: 37107.6306 - val_acc: 0.0012\n",
      "Epoch 213/300\n",
      "3151/3151 [==============================] - 1s 209us/step - loss: 36427.1588 - acc: 9.5208e-04 - val_loss: 37107.6305 - val_acc: 0.0012\n",
      "Epoch 214/300\n",
      "3151/3151 [==============================] - 1s 209us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6274 - val_acc: 0.0012\n",
      "Epoch 215/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.1593 - acc: 9.5208e-04 - val_loss: 37107.6280 - val_acc: 0.0012\n",
      "Epoch 216/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6276 - val_acc: 0.0012\n",
      "Epoch 217/300\n",
      "3151/3151 [==============================] - 1s 210us/step - loss: 36427.1588 - acc: 9.5208e-04 - val_loss: 37107.6272 - val_acc: 0.0012\n",
      "Epoch 218/300\n",
      "3151/3151 [==============================] - 1s 225us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6261 - val_acc: 0.0012\n",
      "Epoch 219/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3151/3151 [==============================] - 1s 218us/step - loss: 36427.1588 - acc: 9.5208e-04 - val_loss: 37107.6257 - val_acc: 0.0012\n",
      "Epoch 220/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36427.1589 - acc: 9.5208e-04 - val_loss: 37107.6271 - val_acc: 0.0012\n",
      "Epoch 221/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6264 - val_acc: 0.0012\n",
      "Epoch 222/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36427.1589 - acc: 9.5208e-04 - val_loss: 37107.6249 - val_acc: 0.0012\n",
      "Epoch 223/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36427.1589 - acc: 9.5208e-04 - val_loss: 37107.6244 - val_acc: 0.0012\n",
      "Epoch 224/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6263 - val_acc: 0.0012\n",
      "Epoch 225/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 36427.1589 - acc: 9.5208e-04 - val_loss: 37107.6232 - val_acc: 0.0012\n",
      "Epoch 226/300\n",
      "3151/3151 [==============================] - 1s 213us/step - loss: 36427.1591 - acc: 9.5208e-04 - val_loss: 37107.6257 - val_acc: 0.0012\n",
      "Epoch 227/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6230 - val_acc: 0.0012\n",
      "Epoch 228/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 36427.1588 - acc: 9.5208e-04 - val_loss: 37107.6233 - val_acc: 0.0012\n",
      "Epoch 229/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.1587 - acc: 9.5208e-04 - val_loss: 37107.6242 - val_acc: 0.0012\n",
      "Epoch 230/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 36427.1587 - acc: 9.5208e-04 - val_loss: 37107.6213 - val_acc: 0.0012\n",
      "Epoch 231/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6237 - val_acc: 0.0012\n",
      "Epoch 232/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6244 - val_acc: 0.0012\n",
      "Epoch 233/300\n",
      "3151/3151 [==============================] - 1s 211us/step - loss: 36427.1585 - acc: 9.5208e-04 - val_loss: 37107.6215 - val_acc: 0.0012\n",
      "Epoch 234/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6236 - val_acc: 0.0012\n",
      "Epoch 235/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 36427.1587 - acc: 9.5208e-04 - val_loss: 37107.6212 - val_acc: 0.0012\n",
      "Epoch 236/300\n",
      "3151/3151 [==============================] - 1s 224us/step - loss: 36427.1584 - acc: 9.5208e-04 - val_loss: 37107.6211 - val_acc: 0.0012\n",
      "Epoch 237/300\n",
      "3151/3151 [==============================] - 1s 223us/step - loss: 36427.1588 - acc: 9.5208e-04 - val_loss: 37107.6222 - val_acc: 0.0012\n",
      "Epoch 238/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 36427.1588 - acc: 9.5208e-04 - val_loss: 37107.6228 - val_acc: 0.0012\n",
      "Epoch 239/300\n",
      "3151/3151 [==============================] - 1s 221us/step - loss: 36427.1592 - acc: 9.5208e-04 - val_loss: 37107.6208 - val_acc: 0.0012\n",
      "Epoch 240/300\n",
      "3151/3151 [==============================] - 1s 214us/step - loss: 36427.1588 - acc: 9.5208e-04 - val_loss: 37107.6186 - val_acc: 0.0012\n",
      "Epoch 241/300\n",
      "3151/3151 [==============================] - 1s 221us/step - loss: 36427.1589 - acc: 9.5208e-04 - val_loss: 37107.6217 - val_acc: 0.0012\n",
      "Epoch 242/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 36427.1589 - acc: 9.5208e-04 - val_loss: 37107.6196 - val_acc: 0.0012\n",
      "Epoch 243/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 36427.1587 - acc: 9.5208e-04 - val_loss: 37107.6213 - val_acc: 0.0012\n",
      "Epoch 244/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6192 - val_acc: 0.0012\n",
      "Epoch 245/300\n",
      "3151/3151 [==============================] - 1s 212us/step - loss: 36427.1589 - acc: 9.5208e-04 - val_loss: 37107.6212 - val_acc: 0.0012\n",
      "Epoch 246/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 36427.1593 - acc: 9.5208e-04 - val_loss: 37107.6192 - val_acc: 0.0012\n",
      "Epoch 247/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6213 - val_acc: 0.0012\n",
      "Epoch 248/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 36427.1589 - acc: 9.5208e-04 - val_loss: 37107.6183 - val_acc: 0.0012\n",
      "Epoch 249/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 36427.1585 - acc: 9.5208e-04 - val_loss: 37107.6208 - val_acc: 0.0012\n",
      "Epoch 250/300\n",
      "3151/3151 [==============================] - 1s 224us/step - loss: 36427.1592 - acc: 9.5208e-04 - val_loss: 37107.6215 - val_acc: 0.0012\n",
      "Epoch 251/300\n",
      "3151/3151 [==============================] - 1s 222us/step - loss: 36427.1591 - acc: 9.5208e-04 - val_loss: 37107.6184 - val_acc: 0.0012\n",
      "Epoch 252/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 36427.1585 - acc: 9.5208e-04 - val_loss: 37107.6198 - val_acc: 0.0012\n",
      "Epoch 253/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 36427.1588 - acc: 9.5208e-04 - val_loss: 37107.6209 - val_acc: 0.0012\n",
      "Epoch 254/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6217 - val_acc: 0.0012\n",
      "Epoch 255/300\n",
      "3151/3151 [==============================] - 1s 222us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6208 - val_acc: 0.0012\n",
      "Epoch 256/300\n",
      "3151/3151 [==============================] - 1s 225us/step - loss: 36427.1589 - acc: 9.5208e-04 - val_loss: 37107.6176 - val_acc: 0.0012\n",
      "Epoch 257/300\n",
      "3151/3151 [==============================] - 1s 221us/step - loss: 36427.1587 - acc: 9.5208e-04 - val_loss: 37107.6186 - val_acc: 0.0012\n",
      "Epoch 258/300\n",
      "3151/3151 [==============================] - 1s 233us/step - loss: 36427.1582 - acc: 9.5208e-04 - val_loss: 37107.6179 - val_acc: 0.0012\n",
      "Epoch 259/300\n",
      "3151/3151 [==============================] - 1s 220us/step - loss: 36427.1584 - acc: 9.5208e-04 - val_loss: 37107.6184 - val_acc: 0.0012\n",
      "Epoch 260/300\n",
      "3151/3151 [==============================] - 1s 222us/step - loss: 36427.1584 - acc: 9.5208e-04 - val_loss: 37107.6194 - val_acc: 0.0012\n",
      "Epoch 261/300\n",
      "3151/3151 [==============================] - 1s 235us/step - loss: 36427.1585 - acc: 9.5208e-04 - val_loss: 37107.6203 - val_acc: 0.0012\n",
      "Epoch 262/300\n",
      "3151/3151 [==============================] - 1s 247us/step - loss: 36427.1587 - acc: 9.5208e-04 - val_loss: 37107.6207 - val_acc: 0.0012\n",
      "Epoch 263/300\n",
      "3151/3151 [==============================] - 1s 228us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6203 - val_acc: 0.0012\n",
      "Epoch 264/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 36427.1588 - acc: 9.5208e-04 - val_loss: 37107.6212 - val_acc: 0.0012\n",
      "Epoch 265/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 36427.1589 - acc: 9.5208e-04 - val_loss: 37107.6184 - val_acc: 0.0012\n",
      "Epoch 266/300\n",
      "3151/3151 [==============================] - 1s 220us/step - loss: 36427.1589 - acc: 9.5208e-04 - val_loss: 37107.6179 - val_acc: 0.0012\n",
      "Epoch 267/300\n",
      "3151/3151 [==============================] - 1s 223us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6185 - val_acc: 0.0012\n",
      "Epoch 268/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 36427.1587 - acc: 9.5208e-04 - val_loss: 37107.6194 - val_acc: 0.0012\n",
      "Epoch 269/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 36427.1588 - acc: 9.5208e-04 - val_loss: 37107.6203 - val_acc: 0.0012\n",
      "Epoch 270/300\n",
      "3151/3151 [==============================] - 1s 264us/step - loss: 36427.1590 - acc: 9.5208e-04 - val_loss: 37107.6209 - val_acc: 0.0012\n",
      "Epoch 271/300\n",
      "3151/3151 [==============================] - 1s 229us/step - loss: 36427.1591 - acc: 9.5208e-04 - val_loss: 37107.6201 - val_acc: 0.0012\n",
      "Epoch 272/300\n",
      "3151/3151 [==============================] - 1s 215us/step - loss: 36427.1592 - acc: 9.5208e-04 - val_loss: 37107.6172 - val_acc: 0.0012\n",
      "Epoch 273/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3151/3151 [==============================] - 1s 223us/step - loss: 36427.1592 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 274/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 275/300\n",
      "3151/3151 [==============================] - 1s 227us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 276/300\n",
      "3151/3151 [==============================] - 1s 249us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 277/300\n",
      "3151/3151 [==============================] - 1s 222us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 278/300\n",
      "3151/3151 [==============================] - 1s 224us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 279/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 280/300\n",
      "3151/3151 [==============================] - 1s 224us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 281/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 282/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 283/300\n",
      "3151/3151 [==============================] - 1s 222us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 284/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 285/300\n",
      "3151/3151 [==============================] - 1s 221us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 286/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 287/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 288/300\n",
      "3151/3151 [==============================] - 1s 220us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 289/300\n",
      "3151/3151 [==============================] - 1s 222us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 290/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 291/300\n",
      "3151/3151 [==============================] - 1s 220us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 292/300\n",
      "3151/3151 [==============================] - 1s 216us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 293/300\n",
      "3151/3151 [==============================] - 1s 217us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 294/300\n",
      "3151/3151 [==============================] - 1s 220us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 295/300\n",
      "3151/3151 [==============================] - 1s 218us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 296/300\n",
      "3151/3151 [==============================] - 1s 219us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 297/300\n",
      "3151/3151 [==============================] - 1s 222us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 298/300\n",
      "3151/3151 [==============================] - 1s 225us/step - loss: 36427.1586 - acc: 9.5208e-04 - val_loss: 37107.6181 - val_acc: 0.0012\n",
      "Epoch 299/300\n",
      "3151/3151 [==============================] - 1s 233us/step - loss: 36472.3453 - acc: 9.5208e-04 - val_loss: 37107.6434 - val_acc: 0.0012\n",
      "Epoch 300/300\n",
      "3151/3151 [==============================] - 1s 231us/step - loss: 36508.4416 - acc: 9.5208e-04 - val_loss: 37107.6656 - val_acc: 0.0012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12532bbe0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train, epochs=300, batch_size=10,validation_data=(X_test,Y_test),shuffle=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1698/1698 [==============================] - 0s 39us/step\n",
      "Accuracy: 0.12\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test,Y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=Y.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
